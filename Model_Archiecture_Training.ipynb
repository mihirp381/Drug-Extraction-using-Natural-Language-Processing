{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6a8be98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/lib/python3.10/site-packages (from en-core-web-lg==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (23.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.5.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.28.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (67.6.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.8.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.14.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "!python3 -m spacy download en_core_web_lg\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e1eeebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "testbcrp = pd.read_csv(\"/code/Final_Annotations_Pubmed.csv\")\n",
    "testbcrp.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2185049",
   "metadata": {},
   "outputs": [],
   "source": [
    "testbcrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33d7037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load pre-trained word2vec model (assuming it's in a .bin file)\n",
    "word_vectors = KeyedVectors.load_word2vec_format('/scratch/BioWordVec_PubMed_MIMICIII_d200.vec.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a1d9741",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(testbcrp['Annotations_final'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "360b4904",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_extracted = pd.read_csv(\"Final_Scraped_Pubmed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a44bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>drug</th>\n",
       "      <th>context</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>PMCID</th>\n",
       "      <th>Protein</th>\n",
       "      <th>context_marked</th>\n",
       "      <th>Annotations_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tyrosine</td>\n",
       "      <td>AlphaSpace has also guided the analysis of pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMC10653122</td>\n",
       "      <td>ABCG2</td>\n",
       "      <td>alphaspace has also guided the analysis of pro...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Chloroquine</td>\n",
       "      <td>AlphaSpace has also guided the analysis of pro...</td>\n",
       "      <td>{'Chloroquinum', 'Aralen', 'Chloroquine', 'Chl...</td>\n",
       "      <td>PMC10653122</td>\n",
       "      <td>ABCG2</td>\n",
       "      <td>alphaspace has also guided the analysis of pro...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ciclosporin</td>\n",
       "      <td>AlphaSpace has also guided the analysis of pro...</td>\n",
       "      <td>{'Ciclosporin', 'Restasis', 'Neoral', 'Sandimm...</td>\n",
       "      <td>PMC10653122</td>\n",
       "      <td>ABCG2</td>\n",
       "      <td>alphaspace has also guided the analysis of pro...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CSCs</td>\n",
       "      <td>Tumor Heterogeneity: Intratumor heterogeneity,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMC10650504</td>\n",
       "      <td>BCRP</td>\n",
       "      <td>tumor heterogeneity: intratumor heterogeneity,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Chloroquine</td>\n",
       "      <td>Tumor Heterogeneity: Intratumor heterogeneity,...</td>\n",
       "      <td>{'Chloroquinum', 'Aralen', 'Chloroquine', 'Chl...</td>\n",
       "      <td>PMC10650504</td>\n",
       "      <td>BCRP</td>\n",
       "      <td>tumor heterogeneity: intratumor heterogeneity,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>Ciclosporin</td>\n",
       "      <td>Tumor Heterogeneity: Intratumor heterogeneity,...</td>\n",
       "      <td>{'Ciclosporin', 'Restasis', 'Neoral', 'Sandimm...</td>\n",
       "      <td>PMC10650504</td>\n",
       "      <td>BCRP</td>\n",
       "      <td>tumor heterogeneity: intratumor heterogeneity,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>Hoechst</td>\n",
       "      <td>Efflux pumps are specialized proteins found in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMC10650504</td>\n",
       "      <td>BCRP</td>\n",
       "      <td>efflux pumps are specialized proteins found in...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>ATP</td>\n",
       "      <td>Efflux pumps are specialized proteins found in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMC10650504</td>\n",
       "      <td>BCRP</td>\n",
       "      <td>efflux pumps are specialized proteins found in...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>cisplatin</td>\n",
       "      <td>Efflux pumps are specialized proteins found in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMC10650504</td>\n",
       "      <td>BCRP</td>\n",
       "      <td>efflux pumps are specialized proteins found in...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>DOX</td>\n",
       "      <td>Efflux pumps are specialized proteins found in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMC10650504</td>\n",
       "      <td>BCRP</td>\n",
       "      <td>efflux pumps are specialized proteins found in...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         drug                                            context  \\\n",
       "0           0     tyrosine  AlphaSpace has also guided the analysis of pro...   \n",
       "1           1  Chloroquine  AlphaSpace has also guided the analysis of pro...   \n",
       "2           2  Ciclosporin  AlphaSpace has also guided the analysis of pro...   \n",
       "3           3         CSCs  Tumor Heterogeneity: Intratumor heterogeneity,...   \n",
       "4           7  Chloroquine  Tumor Heterogeneity: Intratumor heterogeneity,...   \n",
       "5           8  Ciclosporin  Tumor Heterogeneity: Intratumor heterogeneity,...   \n",
       "6           9      Hoechst  Efflux pumps are specialized proteins found in...   \n",
       "7          11          ATP  Efflux pumps are specialized proteins found in...   \n",
       "8          12    cisplatin  Efflux pumps are specialized proteins found in...   \n",
       "9          13          DOX  Efflux pumps are specialized proteins found in...   \n",
       "\n",
       "                                            Synonyms        PMCID Protein  \\\n",
       "0                                                NaN  PMC10653122   ABCG2   \n",
       "1  {'Chloroquinum', 'Aralen', 'Chloroquine', 'Chl...  PMC10653122   ABCG2   \n",
       "2  {'Ciclosporin', 'Restasis', 'Neoral', 'Sandimm...  PMC10653122   ABCG2   \n",
       "3                                                NaN  PMC10650504    BCRP   \n",
       "4  {'Chloroquinum', 'Aralen', 'Chloroquine', 'Chl...  PMC10650504    BCRP   \n",
       "5  {'Ciclosporin', 'Restasis', 'Neoral', 'Sandimm...  PMC10650504    BCRP   \n",
       "6                                                NaN  PMC10650504    BCRP   \n",
       "7                                                NaN  PMC10650504    BCRP   \n",
       "8                                                NaN  PMC10650504    BCRP   \n",
       "9                                                NaN  PMC10650504    BCRP   \n",
       "\n",
       "                                      context_marked  Annotations_final  \n",
       "0  alphaspace has also guided the analysis of pro...                NaN  \n",
       "1  alphaspace has also guided the analysis of pro...                NaN  \n",
       "2  alphaspace has also guided the analysis of pro...                NaN  \n",
       "3  tumor heterogeneity: intratumor heterogeneity,...                NaN  \n",
       "4  tumor heterogeneity: intratumor heterogeneity,...                NaN  \n",
       "5  tumor heterogeneity: intratumor heterogeneity,...                NaN  \n",
       "6  efflux pumps are specialized proteins found in...                NaN  \n",
       "7  efflux pumps are specialized proteins found in...                NaN  \n",
       "8  efflux pumps are specialized proteins found in...                0.0  \n",
       "9  efflux pumps are specialized proteins found in...                NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_extracted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4e496da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================1111111111111111111111111111111111111111\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 1476)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 1476, 200)    20937000    ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 1461, 128)    409728      ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 365, 128)    0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " bidirectional_4 (Bidirectional  (None, 365, 1024)   2625536     ['max_pooling1d_2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 365, 1024)    0           ['bidirectional_4[0][0]']        \n",
      "                                                                                                  \n",
      " bidirectional_5 (Bidirectional  (None, 365, 2048)   16785408    ['dropout_4[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 365, 2048)    0           ['bidirectional_5[0][0]']        \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 365, 1)       2049        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 365)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 365)          0           ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " repeat_vector_2 (RepeatVector)  (None, 2048, 365)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " permute_2 (Permute)            (None, 365, 2048)    0           ['repeat_vector_2[0][0]']        \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 365, 2048)    0           ['dropout_5[0][0]',              \n",
      "                                                                  'permute_2[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 2048)         0           ['multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            2049        ['lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 40,761,770\n",
      "Trainable params: 19,824,770\n",
      "Non-trainable params: 20,937,000\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 232s 916ms/step - loss: 0.4859 - accuracy: 0.8065 - val_loss: 0.4602 - val_accuracy: 0.8138\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 228s 920ms/step - loss: 0.4713 - accuracy: 0.8083 - val_loss: 0.4551 - val_accuracy: 0.8123\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 228s 921ms/step - loss: 0.4482 - accuracy: 0.8091 - val_loss: 0.4354 - val_accuracy: 0.8131\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 228s 921ms/step - loss: 0.4549 - accuracy: 0.8060 - val_loss: 0.4382 - val_accuracy: 0.8138\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 229s 922ms/step - loss: 0.4420 - accuracy: 0.8085 - val_loss: 0.4321 - val_accuracy: 0.8138\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 229s 922ms/step - loss: 0.4336 - accuracy: 0.8089 - val_loss: 0.4281 - val_accuracy: 0.8113\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 229s 923ms/step - loss: 0.4279 - accuracy: 0.8086 - val_loss: 0.4347 - val_accuracy: 0.8149\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 229s 923ms/step - loss: 0.4196 - accuracy: 0.8093 - val_loss: 0.4382 - val_accuracy: 0.7949\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 229s 923ms/step - loss: 0.4002 - accuracy: 0.8182 - val_loss: 0.4218 - val_accuracy: 0.8143\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 229s 924ms/step - loss: 0.3757 - accuracy: 0.8278 - val_loss: 0.4429 - val_accuracy: 0.8103\n",
      "Test accuracy: 0.8103\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.layers import Input, Dense, Flatten, Activation, RepeatVector, Permute, Multiply, Lambda, Bidirectional, LSTM\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import MultiHeadAttention\n",
    "\n",
    "# Prepare the text data\n",
    "texts = testbcrp['context_marked'].tolist()\n",
    "# labels = ra['Relationship_Tag'].values\n",
    "\n",
    "# Prepare tokenizer based on your texts\n",
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
    "\n",
    "print(\"=\"*20 + \"1\"*40)\n",
    "# Manually add the special tokens to the tokenizer's word index\n",
    "special_tokens = ['<e1>', '</e1>', '<e2>', '</e2>']\n",
    "for token in special_tokens:\n",
    "    tokenizer.word_index[token] = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Prepare the embedding matrix\n",
    "embedding_dim = word_vectors.vector_size\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Update vocab_size after adding special tokens\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "# Populate the embedding matrix with word vectors, special tokens are handled separately\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in special_tokens:\n",
    "        # Initialize special tokens with zero or random vectors\n",
    "        embedding_matrix[i] = np.zeros(embedding_dim)  # or np.random.rand(embedding_dim)\n",
    "    elif word in word_vectors:\n",
    "        embedding_matrix[i] = word_vectors[word]\n",
    "\n",
    "# Create the embedding layer\n",
    "embedding_layer = Embedding(input_dim=vocab_size,\n",
    "                            output_dim=embedding_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)\n",
    "\n",
    "# Define the attention mechanism : Simple\n",
    "def attention_layer(inputs, lstm_units):\n",
    "\n",
    "    attention = Dense(1, activation='tanh')(inputs)\n",
    "    attention = Flatten()(attention)\n",
    "    attention = Activation('softmax')(attention)\n",
    "    attention = RepeatVector(lstm_units * 2)(attention)\n",
    "    attention = Permute([2, 1])(attention)\n",
    "    sent_representation = Multiply()([inputs, attention])\n",
    "    sent_representation = Lambda(lambda xin: K.sum(xin, axis=1), output_shape=(lstm_units * 2,))(sent_representation)\n",
    "    return sent_representation\n",
    "# Define the attention mechanism : Advanced\n",
    "# def attention_layer(inputs, lstm_units, num_heads):\n",
    "#     # `inputs` should have shape (batch_size, time_steps, lstm_units*2)\n",
    "#     # `lstm_units` should be the number of hidden units in the LSTM layer\n",
    "#     # `num_heads` is the number of attention heads\n",
    "\n",
    "#     # Multi-head attention layer\n",
    "#     attention_output, attention_weights = MultiHeadAttention(\n",
    "#         num_heads=num_heads,  # Number of attention heads\n",
    "#         key_dim=lstm_units * 2,  # Size of each attention head for query and key\n",
    "#         value_dim=lstm_units * 2  # Size of each attention head for value\n",
    "#     )(query=inputs, value=inputs, key=inputs, return_attention_scores=True)\n",
    "\n",
    "#     # Flatten the attention output to be able to connect to Dense layers later\n",
    "#     sent_representation = Flatten()(attention_output)\n",
    "\n",
    "#     return sent_representation\n",
    "\n",
    "# Model building\n",
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "conv_layer = Conv1D(filters=128, kernel_size=16, activation='relu')(embedded_sequences)\n",
    "max_pooling = MaxPooling1D(pool_size=4)(conv_layer)\n",
    "bilstm_1 = Bidirectional(LSTM(512, return_sequences=True))(max_pooling)\n",
    "dropout_1 = Dropout(0.5)(bilstm_1)  # Apply dropout to the output of the first BiLSTM layer\n",
    "# Second BiLSTM layer\n",
    "bilstm_2 = Bidirectional(LSTM(1024, return_sequences=True))(dropout_1)\n",
    "dropout_2 = Dropout(0.5)(bilstm_2)  # Apply dropout to the output of the second BiLSTM layer\n",
    "# bilstm_output = Bidirectional(LSTM(1024, return_sequences=True))(max_pooling)\n",
    "attention_output = attention_layer(dropout_2, 1024)\n",
    "output = Dense(1, activation='sigmoid')(attention_output)\n",
    "model = Model(sequence_input, output)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "if not np.issubdtype(y_train.dtype, np.number):\n",
    "    y_train = y_train.astype(np.float32)\n",
    "    y_test = y_test.astype(np.float32)\n",
    "    \n",
    "# Convert labels to categorical (if they're not already in binary form)\n",
    "# y_train = to_categorical(y_train, num_classes=3)\n",
    "# y_test = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summarize the model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10\n",
    "          , batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Predict on new data\n",
    "# predictions = model.predict(X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50402635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 23s 180ms/step\n",
      "Optimal threshold according to ROC: 0.13570135831832886\n",
      "Optimal threshold according to Precision-Recall: 0.004818522837013006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "\n",
    "# Assuming you have a trained model and a validation set X_val, y_val\n",
    "\n",
    "# Get the predicted probabilities for the positive class\n",
    "y_scores = model.predict(X_test)\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds_roc = roc_curve(y_test, y_scores)\n",
    "\n",
    "# Calculate precision-recall curve\n",
    "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_scores)\n",
    "\n",
    "# Find the optimal threshold\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold_roc = thresholds_roc[optimal_idx]\n",
    "\n",
    "# Alternatively, if you care about precision-recall balance\n",
    "optimal_idx_pr = np.argmax(precision + recall)\n",
    "optimal_threshold_pr = thresholds_pr[optimal_idx_pr]\n",
    "\n",
    "print(f'Optimal threshold according to ROC: {optimal_threshold_roc}')\n",
    "print(f'Optimal threshold according to Precision-Recall: {optimal_threshold_pr}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd53ffa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6622/6622 [==============================] - 1186s 179ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'new_texts' is a list of new text data you want to predict on\n",
    "new_texts = full_extracted['context_marked'].to_list()  # replace this with your actual new texts\n",
    "new_sequences = tokenizer.texts_to_sequences(new_texts)\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "new_padded_sequences = pad_sequences(new_sequences, maxlen=max_length)\n",
    "\n",
    "# Now make predictions using the model\n",
    "predictions = model.predict(new_padded_sequences)\n",
    "\n",
    "# If you need binary predictions, decide on a threshold and apply it\n",
    "threshold = 0.135 # This is the most common threshold for binary classification\n",
    "binary_predictions = (predictions > threshold).astype(int)\n",
    "\n",
    "# Now 'binary_predictions' contains the final binary predictions for your new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "534b57a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.26 # This is the most common threshold for binary classification\n",
    "# binary_predictions = (predictions > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "62004c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    167218\n",
       "1     44671\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(binary_predictions.reshape(211889,)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9a4163fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_extracted['Predictions'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6d06113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = full_extracted.groupby(['drug'])['Predictions'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c587f812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>drug</th>\n",
       "      <th>context</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>PMCID</th>\n",
       "      <th>Protein</th>\n",
       "      <th>context_marked</th>\n",
       "      <th>Annotations_final</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tyrosine</td>\n",
       "      <td>AlphaSpace has also guided the analysis of pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMC10653122</td>\n",
       "      <td>ABCG2</td>\n",
       "      <td>alphaspace has also guided the analysis of pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.116354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Chloroquine</td>\n",
       "      <td>AlphaSpace has also guided the analysis of pro...</td>\n",
       "      <td>{'Chloroquinum', 'Aralen', 'Chloroquine', 'Chl...</td>\n",
       "      <td>PMC10653122</td>\n",
       "      <td>ABCG2</td>\n",
       "      <td>alphaspace has also guided the analysis of pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.115066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ciclosporin</td>\n",
       "      <td>AlphaSpace has also guided the analysis of pro...</td>\n",
       "      <td>{'Ciclosporin', 'Restasis', 'Neoral', 'Sandimm...</td>\n",
       "      <td>PMC10653122</td>\n",
       "      <td>ABCG2</td>\n",
       "      <td>alphaspace has also guided the analysis of pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.115066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CSCs</td>\n",
       "      <td>Tumor Heterogeneity: Intratumor heterogeneity,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMC10650504</td>\n",
       "      <td>BCRP</td>\n",
       "      <td>tumor heterogeneity: intratumor heterogeneity,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.220331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Chloroquine</td>\n",
       "      <td>Tumor Heterogeneity: Intratumor heterogeneity,...</td>\n",
       "      <td>{'Chloroquinum', 'Aralen', 'Chloroquine', 'Chl...</td>\n",
       "      <td>PMC10650504</td>\n",
       "      <td>BCRP</td>\n",
       "      <td>tumor heterogeneity: intratumor heterogeneity,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.207196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211884</th>\n",
       "      <td>353082</td>\n",
       "      <td>Cisplatin</td>\n",
       "      <td>This is the first report to show that a copper...</td>\n",
       "      <td>{'cisplatino', 'Cisplatin', 'Platinol'}</td>\n",
       "      <td>PMC5926870</td>\n",
       "      <td>BCRP</td>\n",
       "      <td>this is the first report to show that a copper...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211885</th>\n",
       "      <td>353084</td>\n",
       "      <td>progesterone</td>\n",
       "      <td>The expression levels of mRNA for multidrug re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMC5926724</td>\n",
       "      <td>BCRP</td>\n",
       "      <td>the expression levels of mrna for multidrug re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211886</th>\n",
       "      <td>353085</td>\n",
       "      <td>estrogen</td>\n",
       "      <td>The expression levels of mRNA for multidrug re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMC5926724</td>\n",
       "      <td>BCRP</td>\n",
       "      <td>the expression levels of mrna for multidrug re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211887</th>\n",
       "      <td>353086</td>\n",
       "      <td>Chloroquine</td>\n",
       "      <td>The expression levels of mRNA for multidrug re...</td>\n",
       "      <td>{'Chloroquinum', 'Aralen', 'Chloroquine', 'Chl...</td>\n",
       "      <td>PMC5926724</td>\n",
       "      <td>BCRP</td>\n",
       "      <td>the expression levels of mrna for multidrug re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211888</th>\n",
       "      <td>353087</td>\n",
       "      <td>Ciclosporin</td>\n",
       "      <td>The expression levels of mRNA for multidrug re...</td>\n",
       "      <td>{'Ciclosporin', 'Restasis', 'Neoral', 'Sandimm...</td>\n",
       "      <td>PMC5926724</td>\n",
       "      <td>BCRP</td>\n",
       "      <td>the expression levels of mrna for multidrug re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211889 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0          drug  \\\n",
       "0                0      tyrosine   \n",
       "1                1   Chloroquine   \n",
       "2                2   Ciclosporin   \n",
       "3                3          CSCs   \n",
       "4                7   Chloroquine   \n",
       "...            ...           ...   \n",
       "211884      353082     Cisplatin   \n",
       "211885      353084  progesterone   \n",
       "211886      353085      estrogen   \n",
       "211887      353086   Chloroquine   \n",
       "211888      353087   Ciclosporin   \n",
       "\n",
       "                                                  context  \\\n",
       "0       AlphaSpace has also guided the analysis of pro...   \n",
       "1       AlphaSpace has also guided the analysis of pro...   \n",
       "2       AlphaSpace has also guided the analysis of pro...   \n",
       "3       Tumor Heterogeneity: Intratumor heterogeneity,...   \n",
       "4       Tumor Heterogeneity: Intratumor heterogeneity,...   \n",
       "...                                                   ...   \n",
       "211884  This is the first report to show that a copper...   \n",
       "211885  The expression levels of mRNA for multidrug re...   \n",
       "211886  The expression levels of mRNA for multidrug re...   \n",
       "211887  The expression levels of mRNA for multidrug re...   \n",
       "211888  The expression levels of mRNA for multidrug re...   \n",
       "\n",
       "                                                 Synonyms        PMCID  \\\n",
       "0                                                     NaN  PMC10653122   \n",
       "1       {'Chloroquinum', 'Aralen', 'Chloroquine', 'Chl...  PMC10653122   \n",
       "2       {'Ciclosporin', 'Restasis', 'Neoral', 'Sandimm...  PMC10653122   \n",
       "3                                                     NaN  PMC10650504   \n",
       "4       {'Chloroquinum', 'Aralen', 'Chloroquine', 'Chl...  PMC10650504   \n",
       "...                                                   ...          ...   \n",
       "211884            {'cisplatino', 'Cisplatin', 'Platinol'}   PMC5926870   \n",
       "211885                                                NaN   PMC5926724   \n",
       "211886                                                NaN   PMC5926724   \n",
       "211887  {'Chloroquinum', 'Aralen', 'Chloroquine', 'Chl...   PMC5926724   \n",
       "211888  {'Ciclosporin', 'Restasis', 'Neoral', 'Sandimm...   PMC5926724   \n",
       "\n",
       "       Protein                                     context_marked  \\\n",
       "0        ABCG2  alphaspace has also guided the analysis of pro...   \n",
       "1        ABCG2  alphaspace has also guided the analysis of pro...   \n",
       "2        ABCG2  alphaspace has also guided the analysis of pro...   \n",
       "3         BCRP  tumor heterogeneity: intratumor heterogeneity,...   \n",
       "4         BCRP  tumor heterogeneity: intratumor heterogeneity,...   \n",
       "...        ...                                                ...   \n",
       "211884    BCRP  this is the first report to show that a copper...   \n",
       "211885    BCRP  the expression levels of mrna for multidrug re...   \n",
       "211886    BCRP  the expression levels of mrna for multidrug re...   \n",
       "211887    BCRP  the expression levels of mrna for multidrug re...   \n",
       "211888    BCRP  the expression levels of mrna for multidrug re...   \n",
       "\n",
       "        Annotations_final  Predictions  \n",
       "0                     NaN     0.116354  \n",
       "1                     NaN     0.115066  \n",
       "2                     NaN     0.115066  \n",
       "3                     NaN     0.220331  \n",
       "4                     NaN     0.207196  \n",
       "...                   ...          ...  \n",
       "211884                NaN     0.046435  \n",
       "211885                NaN     0.040444  \n",
       "211886                NaN     0.029228  \n",
       "211887                NaN     0.041686  \n",
       "211888                NaN     0.041686  \n",
       "\n",
       "[211889 rows x 9 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "005e2683",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = full_extracted.groupby('drug').agg({\n",
    "    'Predictions': 'mean',\n",
    "    'PMCID': lambda x: list(x.unique())\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "adda80a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"Final_Predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
